{
  "actions": [],
  "creation": "2026-01-06 00:00:00.000000",
  "doctype": "DocType",
  "engine": "InnoDB",
  "field_order": [
    "smart_pipeline_section",
    "enable_smart_pipeline",
    "enable_contextual_enrichment",
    "enable_vision_processing",
    "column_break_smart",
    "enable_semantic_chunking",
    "enable_hybrid_search",
    "model_selection_section",
    "embedding_model_v2",
    "context_enrichment_model",
    "column_break_models",
    "vision_model",
    "reranker_model",
    "embedding_section",
    "embedding_provider",
    "ollama_section_break",
    "ollama_model",
    "ollama_url",
    "ollama_vram_info",
    "openrouter_section_break",
    "openrouter_api_key",
    "openrouter_model",
    "embedding_info_section",
    "embedding_dimension",
    "qdrant_section",
    "qdrant_mode",
    "qdrant_path",
    "collection_name",
    "column_break_qdrant",
    "qdrant_host",
    "qdrant_port",
    "qdrant_api_key",
    "processing_section",
    "chunk_size",
    "chunk_overlap",
    "max_file_size_mb",
    "column_break_processing",
    "enabled_file_types",
    "enable_auto_processing",
    "actions_section",
    "actions_html",
    "status_section",
    "connection_status"
  ],
  "fields": [
    {
      "fieldname": "smart_pipeline_section",
      "fieldtype": "Section Break",
      "label": "Smart Pipeline Configuration"
    },
    {
      "default": "1",
      "description": "Use multi-step intelligent processing with contextual enrichment, vision, and semantic chunking",
      "fieldname": "enable_smart_pipeline",
      "fieldtype": "Check",
      "label": "Enable Smart Pipeline"
    },
    {
      "default": "1",
      "depends_on": "eval:doc.enable_smart_pipeline",
      "description": "Prepend situating context to each chunk before embedding (Anthropic's contextual retrieval approach)",
      "fieldname": "enable_contextual_enrichment",
      "fieldtype": "Check",
      "label": "Enable Contextual Enrichment"
    },
    {
      "default": "1",
      "depends_on": "eval:doc.enable_smart_pipeline",
      "description": "Use vision models to describe images, charts, and infographics",
      "fieldname": "enable_vision_processing",
      "fieldtype": "Check",
      "label": "Enable Vision Processing"
    },
    {
      "fieldname": "column_break_smart",
      "fieldtype": "Column Break"
    },
    {
      "default": "1",
      "depends_on": "eval:doc.enable_smart_pipeline",
      "description": "Use structure-aware chunking instead of fixed character-based chunking",
      "fieldname": "enable_semantic_chunking",
      "fieldtype": "Check",
      "label": "Enable Semantic Chunking"
    },
    {
      "default": "1",
      "depends_on": "eval:doc.enable_smart_pipeline",
      "description": "Use BM25 sparse vectors alongside dense embeddings for better retrieval",
      "fieldname": "enable_hybrid_search",
      "fieldtype": "Check",
      "label": "Enable Hybrid Search"
    },
    {
      "fieldname": "model_selection_section",
      "fieldtype": "Section Break",
      "label": "Model Selection",
      "depends_on": "eval:doc.enable_smart_pipeline"
    },
    {
      "default": "qwen/qwen3-embedding-8b",
      "depends_on": "eval:doc.enable_smart_pipeline",
      "description": "OpenRouter model ID for embeddings (e.g., qwen/qwen3-embedding-8b, voyageai/voyage-3-large)",
      "fieldname": "embedding_model_v2",
      "fieldtype": "Data",
      "label": "Embedding Model"
    },
    {
      "default": "google/gemini-3-flash-preview",
      "depends_on": "eval:doc.enable_contextual_enrichment",
      "description": "OpenRouter model ID for generating chunk context (e.g., google/gemini-3-flash-preview)",
      "fieldname": "context_enrichment_model",
      "fieldtype": "Data",
      "label": "Context Enrichment Model"
    },
    {
      "fieldname": "column_break_models",
      "fieldtype": "Column Break"
    },
    {
      "default": "qwen/qwen3-vl-235b-a22b-instruct",
      "depends_on": "eval:doc.enable_vision_processing",
      "description": "OpenRouter model ID for image/chart understanding (e.g., qwen/qwen3-vl-235b-a22b-instruct)",
      "fieldname": "vision_model",
      "fieldtype": "Data",
      "label": "Vision Model"
    },
    {
      "default": "cohere/rerank-v3",
      "depends_on": "eval:doc.enable_hybrid_search",
      "description": "Model for reranking search results (e.g., cohere/rerank-v3)",
      "fieldname": "reranker_model",
      "fieldtype": "Data",
      "label": "Reranker Model"
    },
    {
      "fieldname": "embedding_section",
      "fieldtype": "Section Break",
      "label": "Legacy Embedding Provider",
      "collapsible": 1,
      "collapsible_depends_on": "eval:doc.enable_smart_pipeline"
    },
    {
      "default": "Local (Ollama)",
      "fieldname": "embedding_provider",
      "fieldtype": "Select",
      "label": "Embedding Provider",
      "options": "Local (Ollama)\nOpenRouter",
      "reqd": 1
    },
    {
      "fieldname": "ollama_section_break",
      "fieldtype": "Section Break",
      "label": "Ollama Settings",
      "depends_on": "eval:doc.embedding_provider=='Local (Ollama)'"
    },
    {
      "default": "nomic-embed-text",
      "depends_on": "eval:doc.embedding_provider=='Local (Ollama)'",
      "description": "Select the Ollama embedding model to use",
      "fieldname": "ollama_model",
      "fieldtype": "Select",
      "label": "Ollama Model",
      "options": "nomic-embed-text\nmxbai-embed-large\nall-minilm\nsnowflake-arctic-embed"
    },
    {
      "default": "http://host.docker.internal:11434",
      "depends_on": "eval:doc.embedding_provider=='Local (Ollama)'",
      "description": "Ollama API URL. Use host.docker.internal for Docker/K8s, or localhost for local development",
      "fieldname": "ollama_url",
      "fieldtype": "Data",
      "label": "Ollama URL"
    },
    {
      "fieldname": "ollama_vram_info",
      "fieldtype": "HTML",
      "depends_on": "eval:doc.embedding_provider=='Local (Ollama)'",
      "options": "<div class=\"alert alert-info\" style=\"margin-top: 10px;\"><strong>VRAM Requirements:</strong><ul style=\"margin-bottom: 0;\"><li><b>nomic-embed-text</b> (768 dims): ~275 MB VRAM - <em>Recommended for most use cases</em></li><li><b>mxbai-embed-large</b> (1024 dims): ~670 MB VRAM - <em>Higher quality embeddings</em></li><li><b>all-minilm</b> (384 dims): ~45 MB VRAM - <em>Lightweight, fast</em></li><li><b>snowflake-arctic-embed</b> (1024 dims): ~670 MB VRAM - <em>Good for retrieval</em></li></ul><p style=\"margin-top: 10px; margin-bottom: 0;\">Run <code>ollama pull &lt;model-name&gt;</code> to download the model first.</p></div>"
    },
    {
      "fieldname": "openrouter_section_break",
      "fieldtype": "Section Break",
      "label": "OpenRouter Settings",
      "depends_on": "eval:doc.embedding_provider=='OpenRouter'"
    },
    {
      "depends_on": "eval:doc.embedding_provider=='OpenRouter'",
      "fieldname": "openrouter_api_key",
      "fieldtype": "Password",
      "label": "OpenRouter API Key",
      "mandatory_depends_on": "eval:doc.embedding_provider=='OpenRouter'",
      "hide_password_strength": 1
    },
    {
      "default": "openai/text-embedding-3-small",
      "depends_on": "eval:doc.embedding_provider=='OpenRouter'",
      "description": "Embedding model to use via OpenRouter. Dimensions are automatically set based on the model.",
      "fieldname": "openrouter_model",
      "fieldtype": "Select",
      "label": "OpenRouter Model",
      "options": "openai/text-embedding-3-small\nopenai/text-embedding-3-large\nopenai/text-embedding-ada-002\ncohere/embed-english-v3.0\ncohere/embed-multilingual-v3.0\ncohere/embed-english-light-v3.0"
    },
    {
      "fieldname": "embedding_info_section",
      "fieldtype": "Section Break",
      "label": "Embedding Information",
      "collapsible": 1
    },
    {
      "description": "Automatically set based on model selection. This determines the vector size in Qdrant.",
      "fieldname": "embedding_dimension",
      "fieldtype": "Int",
      "label": "Embedding Dimension",
      "read_only": 1
    },
    {
      "fieldname": "qdrant_section",
      "fieldtype": "Section Break",
      "label": "Qdrant Vector Database"
    },
    {
      "default": "Embedded (Persistent)",
      "fieldname": "qdrant_mode",
      "fieldtype": "Select",
      "label": "Qdrant Mode",
      "options": "Embedded (In-Memory)\nEmbedded (Persistent)\nServer",
      "reqd": 1
    },
    {
      "default": "./sites/{site_name}/private/qdrant",
      "depends_on": "eval:doc.qdrant_mode=='Embedded (Persistent)'",
      "description": "Path for persistent embedded Qdrant storage",
      "fieldname": "qdrant_path",
      "fieldtype": "Data",
      "label": "Qdrant Data Path"
    },
    {
      "default": "drive_documents",
      "fieldname": "collection_name",
      "fieldtype": "Data",
      "label": "Collection Name",
      "reqd": 1
    },
    {
      "fieldname": "column_break_qdrant",
      "fieldtype": "Column Break"
    },
    {
      "default": "localhost",
      "depends_on": "eval:doc.qdrant_mode=='Server'",
      "fieldname": "qdrant_host",
      "fieldtype": "Data",
      "label": "Qdrant Host"
    },
    {
      "default": "6333",
      "depends_on": "eval:doc.qdrant_mode=='Server'",
      "fieldname": "qdrant_port",
      "fieldtype": "Int",
      "label": "Qdrant Port"
    },
    {
      "depends_on": "eval:doc.qdrant_mode=='Server'",
      "description": "Optional: Required if Qdrant server has authentication enabled",
      "fieldname": "qdrant_api_key",
      "fieldtype": "Password",
      "label": "Qdrant API Key",
      "hide_password_strength": 1
    },
    {
      "fieldname": "processing_section",
      "fieldtype": "Section Break",
      "label": "Document Processing"
    },
    {
      "default": "1000",
      "fieldname": "chunk_size",
      "fieldtype": "Int",
      "label": "Chunk Size (characters)",
      "reqd": 1
    },
    {
      "default": "200",
      "fieldname": "chunk_overlap",
      "fieldtype": "Int",
      "label": "Chunk Overlap (characters)",
      "reqd": 1
    },
    {
      "default": "50",
      "description": "Skip files larger than this size",
      "fieldname": "max_file_size_mb",
      "fieldtype": "Int",
      "label": "Max File Size (MB)"
    },
    {
      "fieldname": "column_break_processing",
      "fieldtype": "Column Break"
    },
    {
      "default": "pdf\ntxt\ndocx\nmd",
      "description": "One file extension per line (without dot)",
      "fieldname": "enabled_file_types",
      "fieldtype": "Small Text",
      "label": "Enabled File Types"
    },
    {
      "default": "1",
      "description": "Automatically process new Drive files",
      "fieldname": "enable_auto_processing",
      "fieldtype": "Check",
      "label": "Enable Automatic Processing"
    },
    {
      "fieldname": "actions_section",
      "fieldtype": "Section Break",
      "label": "Actions"
    },
    {
      "fieldname": "actions_html",
      "fieldtype": "HTML",
      "label": "Action Buttons",
      "options": "<div style=\"display: flex; gap: 12px; flex-wrap: wrap; align-items: center; margin-bottom: 20px;\"><button id=\"test-connections-btn\" class=\"btn btn-primary btn-sm\">Test Connections</button><button id=\"process-existing-btn\" class=\"btn btn-warning btn-sm\">Process Existing Files</button><button id=\"refresh-stats-btn\" class=\"btn btn-default btn-sm\">Refresh Stats</button></div><div id=\"pipeline-stats-display\" class=\"alert alert-info\" style=\"margin-top: 15px;\">Click Refresh Stats button to load statistics</div>"
    },
    {
      "fieldname": "status_section",
      "fieldtype": "Section Break",
      "label": "Connection Status",
      "collapsible": 1
    },
    {
      "fieldname": "connection_status",
      "fieldtype": "Data",
      "label": "Connection Status",
      "read_only": 1
    }
  ],
  "issingle": 1,
  "links": [],
  "modified": "2026-01-06 14:00:00.000000",
  "modified_by": "Administrator",
  "module": "Frappe Data Pipelines",
  "name": "Data Pipeline Settings",
  "owner": "Administrator",
  "permissions": [
    {
      "create": 1,
      "delete": 1,
      "email": 1,
      "print": 1,
      "read": 1,
      "role": "System Manager",
      "share": 1,
      "write": 1
    }
  ],
  "sort_field": "creation",
  "sort_order": "DESC"
}
